{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:15<00:00, 10.25it/s, current max=172] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tqdm\n",
    "#import libs.functions as _fn\n",
    "speaker_dir = '/mnt/nvme2tb/datasets/voxceleb2/sorted/train/id00012'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "samples = os.listdir(speaker_dir)\n",
    "maxs = {}\n",
    "pbar = tqdm.tqdm(samples)\n",
    "for f in pbar:\n",
    "    audio, sr = librosa.load(os.path.join(speaker_dir,f), sr=16000, mono=True)\n",
    "    s = librosa.stft(y=audio,\n",
    "                     n_fft=400,\n",
    "                     hop_length=160,\n",
    "                     window='hamming',\n",
    "                     center=True)\n",
    "    S = np.abs(s)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sr,\n",
    "                                        n_fft=400,\n",
    "                                        fmin=20,\n",
    "                                        fmax=8000,\n",
    "                                        htk=True,\n",
    "                                        n_mels=64)\n",
    "    F = np.dot(mel_basis, S)\n",
    "    maxs[f] = np.max(F)\n",
    "    pbar.set_postfix({'current max': np.max([el for el in maxs.values()])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L5fo1OvuXIg_00060.m4a : 172.01607\n"
     ]
    }
   ],
   "source": [
    "for key, value in maxs.items():\n",
    "    if value > 100:\n",
    "        print(key, \":\", value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "csv_dir = './diffs'\n",
    "csv_list = os.listdir(csv_dir)\n",
    "csvs = np.zeros((64, 0))\n",
    "for f in csv_list:\n",
    "    data = np.genfromtxt(os.path.join(csv_dir, f), delimiter=',', skip_header=False) # np.loadtxt(os.path.join(csv_dir, f))\n",
    "    # print(data.shape)\n",
    "    csvs = np.concatenate((csvs, data), axis=1)\n",
    "print(csvs.shape)\n",
    "np.save('combined.dat', csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs.shape\n",
    "import librosa.display\n",
    "librosa.display.specshow(csvs, sr=16000, hop_length=160, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csvs\n",
    "gen = np.empty(data.shape)\n",
    "means = np.mean(data, axis=1)\n",
    "stds = np.std(data, axis=1)\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    gen[i] = np.random.normal(mean, std, data.shape[1])\n",
    "librosa.display.specshow(gen, sr=16000, hop_length=160, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data), np.min(data), np.max(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsf.write('signal.wav', signal, samplerate=sr)\\nsf.write('resampled.wav', signal, samplerate=sr)\\n#print(signal.shape, '16000')\\nambient, sr = librosa.load(fa, mono=True)\\nlibrosa.resample(ambient, sr, 16000, fix=True)\\nambient = ambient[:signal.shape[0]]\\nsf.write('ambient.wav', ambient, samplerate=sr)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import soundfile as sf\n",
    "import string\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "signal_dir_path = '/mnt/nvme2tb/datasets/voxceleb2/sorted/train'\n",
    "ambient_dir_path = '/mnt/nvme2tb/datasets/music-genres-kaggle/Data/genres_original'\n",
    "\n",
    "signal_dirs = [f.path for f in os.scandir(signal_dir_path) if f.is_dir()]\n",
    "ambient_dirs = [f.path for f in os.scandir(ambient_dir_path) if f.is_dir()]\n",
    "#print(signal_dirs)\n",
    "\n",
    "signal_index = []\n",
    "for sigdir in signal_dirs:\n",
    "    signal_index.extend([os.path.join(sigdir, el) for el in os.listdir(sigdir)])\n",
    "#signal_index = os.listdir(signal_dir)\n",
    "ambient_index = []\n",
    "for ambdir in ambient_dirs:\n",
    "    ambient_index.extend([os.path.join(ambdir, el) for el in os.listdir(ambdir)])\n",
    "\n",
    "def A(raw_audio, sr=16000, n_mels=40, frame_length_ms=25, hop_ms=10):\n",
    "    # 512 (32ms) vs 256 (16ms) when sr=16000 / optimal for speech is (512) 23ms with sr=22050\n",
    "    # \"frame length=25ms, frame shift=10ms\" / 1/16000 => window = 400, hop = 160\n",
    "    frame_length = int(frame_length_ms * sr / 1000)\n",
    "    hop = int(hop_ms * sr / 1000)\n",
    "    S = np.abs(\n",
    "        librosa.stft(y=raw_audio,\n",
    "                     n_fft=frame_length,\n",
    "                     hop_length=hop,\n",
    "                     window='hamming',\n",
    "                     center=True))**2\n",
    "    # Calculating mel_basis\n",
    "    mel_basis = librosa.filters.mel(sr=sr,\n",
    "                                    n_fft=frame_length,\n",
    "                                    fmin=20,\n",
    "                                    fmax=8000,\n",
    "                                    htk=True,\n",
    "                                    n_mels=n_mels)\n",
    "    F = np.dot(mel_basis, S)\n",
    "    return F\n",
    "\n",
    "\n",
    "def Z(F):\n",
    "    Fdb = librosa.power_to_db(F, ref=np.max)[:, :-1]\n",
    "    return Fdb\n",
    "\n",
    "def std(spg):\n",
    "    return (spg + 40.) / 40.\n",
    "\n",
    "\n",
    "# print(signal)  \n",
    "#signal, sr = torchaudio.load(f1, normalize=True)\n",
    "#transform = torchaudio.transforms.Resample(sr, 16000)\n",
    "#print(signal.shape, sr)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "sf.write('signal.wav', signal, samplerate=sr)\n",
    "sf.write('resampled.wav', signal, samplerate=sr)\n",
    "#print(signal.shape, '16000')\n",
    "ambient, sr = librosa.load(fa, mono=True)\n",
    "librosa.resample(ambient, sr, 16000, fix=True)\n",
    "ambient = ambient[:signal.shape[0]]\n",
    "sf.write('ambient.wav', ambient, samplerate=sr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/home/sergey/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#print(j)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     signal, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(signal.shape, sr)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     librosa\u001b[38;5;241m.\u001b[39mresample(signal, sr, \u001b[38;5;241m16000\u001b[39m, fix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    172\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/librosa/core/audio.py:604\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m soxr\u001b[38;5;241m.\u001b[39mresample(y\u001b[38;5;241m.\u001b[39mT, orig_sr, target_sr, quality\u001b[38;5;241m=\u001b[39mres_type)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 604\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[1;32m    607\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, n_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/resampy/core.py:120\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m x_2d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, axis)\u001b[38;5;241m.\u001b[39mreshape((x\u001b[38;5;241m.\u001b[39mshape[axis], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    119\u001b[0m y_2d \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, axis)\u001b[38;5;241m.\u001b[39mreshape((y\u001b[38;5;241m.\u001b[39mshape[axis], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 120\u001b[0m \u001b[43mresample_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp_win\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "for j in range(100000):\n",
    "    #print(j)\n",
    "    signal, sr = librosa.load(random.choice(signal_index), mono=True)\n",
    "    #print(signal.shape, sr)\n",
    "    librosa.resample(signal, sr, 16000, fix=True)\n",
    "\n",
    "    ambient, sr = librosa.load(random.choice(ambient_index), mono=True)\n",
    "    #print(ambient.shape, sr)\n",
    "    librosa.resample(ambient, sr, 16000, fix=True)\n",
    "    start = random.randint(0, ambient.shape[0]-signal.shape[0])\n",
    "    ambient_cut = ambient[start:start+signal.shape[0]]\n",
    "\n",
    "    mixed = np.add(signal*.75, ambient_cut*.25)\n",
    "\n",
    "    #sf.write('signal.wav', signal, samplerate=22050)\n",
    "    #sf.write('ambient.wav', ambient_cut, samplerate=22050)\n",
    "    #sf.write('mixed.wav', mixed, samplerate=22050)\n",
    "\n",
    "    spgd = std(Z(A(signal)))\n",
    "    spgs = std(Z(A(mixed)))\n",
    "    spgdiff = spgs-spgd\n",
    "    letters = string.ascii_lowercase\n",
    "    fname = './diffs-music-louder/' + ''.join(random.choice(letters) for i in range(10)) + '.csv'\n",
    "    np.savetxt(fname, spgdiff, delimiter=\",\")\n",
    "    #print(np.mean(spgdiff), np.var(spgdiff), np.std(spgdiff))\n",
    "    #for i in range(spgdiff.shape[0]):\n",
    "    #    print(np.mean(spgdiff[i]), np.var(spgdiff[i]), np.std(spgdiff[i]))\n",
    "#librosa.display.specshow(spgdiff, sr=16000, hop_length=160, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(spgs, sr=16000, hop_length=160, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(spgd, sr=16000, hop_length=160, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.load('/mnt/nvme2tb/datasets/voxceleb2/spectrogram_noises/noises.npy')\n",
    "b = np.load('music-louder.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((a,b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, b.shape, c.shape\n",
    "np.save('/mnt/nvme2tb/datasets/voxceleb2/spectrogram_noises/noises_louder.npy', c)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f96abb89c86116bcf02e4e9d99eb80b547362647ff93c7cbb55d52a8a5c84d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
